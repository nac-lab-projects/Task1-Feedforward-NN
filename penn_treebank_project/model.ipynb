{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a415556c",
   "metadata": {},
   "source": [
    "### **`model.ipynb` — Neural Network Architecture**\n",
    "\n",
    "- *In this notebook, we define the architecture of our Feedforward Neural Network (FNN).*\n",
    "\n",
    "- *The model consists of one input layer, two hidden layers (each using the ReLU activation function), and one output layer.*\n",
    "\n",
    "- *This structure allows the network to learn complex patterns between words for next-word prediction tasks using the Penn Treebank dataset.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aded00",
   "metadata": {},
   "source": [
    "*Here, we import PyTorch and its neural network module (`torch.nn`), which provides the essential building blocks for defining and training deep learning models.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f986334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af48c50",
   "metadata": {},
   "source": [
    "*In this step, we define our model class using PyTorch’s `nn.Module`.*\n",
    "\n",
    "*Each layer performs a linear transformation followed by a ReLU activation, except for the output layer, which gives raw predictions.*\n",
    "\n",
    "*The `forward()` method defines how data flows through the layers — from input to output.*\n",
    "\n",
    "---\n",
    "\n",
    "### *Activation Functions Used*\n",
    "\n",
    "* **Hidden Layers → ReLU (`max(0, z)`):**\n",
    "  *We use ReLU in hidden layers because it avoids vanishing gradients, allows the network to focus on important patterns (sparsity), and is computationally efficient. It helps the network learn faster and better, especially as the model gets deeper.*\n",
    "\n",
    "* **Output Layer → Softmax:**\n",
    "  *We use Softmax in the output layer because it converts the raw output scores into probabilities for each word in the vocabulary. The highest probability indicates the predicted next word.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2b1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    \"\"\"Simple feedforward neural network for next-word prediction\"\"\"\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efec5c1",
   "metadata": {},
   "source": [
    "*This code creates an instance of the model using example dimensions for each layer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b9c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNN(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FeedforwardNN(input_size=100, hidden_size1=64, hidden_size2=32, output_size=10)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
