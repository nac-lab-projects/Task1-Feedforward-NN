{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a44be76",
   "metadata": {},
   "source": [
    "### *Step 1: Imports*\n",
    "\n",
    "*Import necessary modules and functions. `data_utils` contains preprocessing functions, `model` defines our neural network, and `train_utils` handles the training loop.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3edf5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from data_utils import load_and_tokenize, build_vocab, prepare_data\n",
    "from model import FeedforwardNN\n",
    "from train_utils import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2cc46",
   "metadata": {},
   "source": [
    "### *Step 2: Load Dataset*\n",
    "\n",
    "*Specify the path to the Penn Treebank dataset and load the training and validation sentences using our `load_and_tokenize` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84cbbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = load_and_tokenize(\"ptbdataset/ptb.train.txt\")\n",
    "val_sentences   = load_and_tokenize(\"ptbdataset/ptb.valid.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f59e06",
   "metadata": {},
   "source": [
    "### *Step 3: Build Vocabulary and Prepare Data*\n",
    "\n",
    "*Create word-to-index and index-to-word mappings using `build_vocab`. Then, `prepare_data` converts tokenized sentences into numerical sequences for model training. Inputs are sequences of words, and outputs are the next words.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b323319",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word = build_vocab(train_sentences)\n",
    "train_inputs, train_outputs, max_seq_len = prepare_data(train_sentences, word_to_index)\n",
    "val_inputs, val_outputs, _ = prepare_data(val_sentences, word_to_index, max_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923b53c",
   "metadata": {},
   "source": [
    "### *Step 4: Initialize Model*\n",
    "\n",
    "*Define the neural network with input size equal to the sequence length, two hidden layers (128 and 64 neurons), and output size equal to the vocabulary size. We then create an instance of `FeedforwardNN`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "debb86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = max_seq_len - 1\n",
    "embedding_dim = 50\n",
    "hidden_size1, hidden_size2 = 128, 64\n",
    "vocab_size = len(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f744d1f",
   "metadata": {},
   "source": [
    "### *Step 5: Train the Model*\n",
    "\n",
    "*Train the neural network using `train_model`, which handles batching, loss computation, backpropagation, and validation. For simplicity, we predict only the first next word in each sequence.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e3ebb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate with correct signature\n",
    "model = FeedforwardNN(seq_len=max_seq_len-1, \n",
    "                      embedding_dim=embedding_dim, \n",
    "                      hidden1=hidden_size1, \n",
    "                      hidden2=hidden_size2, \n",
    "                      vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97ec2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 5.0188\n",
      "Validation Loss: 3.6656\n",
      "Epoch 2/5, Loss: 2.4526\n",
      "Validation Loss: 2.6854\n",
      "Epoch 3/5, Loss: 1.1483\n",
      "Validation Loss: 2.3516\n",
      "Epoch 4/5, Loss: 0.4708\n",
      "Validation Loss: 2.3418\n",
      "Epoch 5/5, Loss: 0.1720\n",
      "Validation Loss: 2.5293\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_inputs, train_outputs, val_inputs, val_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
